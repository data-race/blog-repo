---
title: Chapter 3 Training the Image Classifier
tags:
  - ios开发
categories:
  - iOS开发
date: 2023-07-17 20:17:29
---
#ios开发 

本章学习通过Create ML套件来训练一个零食种类的分类器。通过使用Create ML框架，可以很容易得到想要的模型。

## 数据集
使用的数据集是本书的作者整理出的零食数据集，一共有20种不同的零食，每种零食有350张图片，其中250张用于训练，50张用于验证，50张用于测试。在CreateML中，数据集被组织成文件夹的形式，每个类别用一个子文件夹。

![](img/CB2FCA18-267B-43A6-AE68-33E3700D68A6.png
)

## CreateML
我们首先创建一个macOS playground，记住必须是macOS的，否则没有CreateML框架，然后输入以下代码并运行：
``` swift
import CreateMLUI

let builder = MLImageClassifierBuilder()
builder.showInLiveView()
```

运行后，会发现Xcode右侧出现了有关模型训练的图形界面，可以拖拽/选择等方式加入训练集，测试集等，也可以设置训练轮数。

![](img/2FD703CF-A6E5-4BF4-9BFB-363D74F6A56A.png
)
之后就会开启训练流程，训练过程会实时显示在下方。直观上来说，训练还是比较快的，这是由于使用了*迁移训练*，之后会再介绍。
另外，Xcode会提示Create ML的所有功能已经被苹果开发成了一个APP，https://developer.apple.com/machine-learning/resources/，并在WWDC 2019上发布。虽然仍然可以使用Create ML框架进行训练。

在进行训练时，CreateML实际上不会把所有图片一次性装入内存，只是在内存中存储它们的元信息，并在需要时读取图片，这样可以一次性使用非常多的图片进行训练。

## 如何创建数据集
这一节作者介绍创建数据集的一些经验。创建数据集是机器学习中最费时费力的部分。作者创建的数据集取自谷歌开放图片数据集，这个数据集非常大，有超过900万张图片被组织成上千个类别。在这个数据集中，谷歌没有直接存储图片，而是给出每个图片的元信息，告诉使用者在哪里可以下载图片，因此使用者需要使用自己的脚本来逐个下载这些图片。在得到图片后，还要进行手动的清理：
1. 有一些图片包含多个物体，其中有一些不是我们关心的，这类图片要去除
2. 有些图片包含的物体的界线是模糊的，例如松饼和饼干，因此这类图片要去除
3. 要面向任务，我们试图对零食进行分类，其背景一般是在家里或者办公室。但是长在树上的香蕉不是我们关注的。
4. 不能使用分辨率太小的图片，因为CreateML的模型会把图片缩放到299 * 299，所以太小的图片是不需要的。

## 迁移学习
在第一章我们介绍了迁移学习，在已有的、功能类似的模型上，通过使用自己的数据集进行再次训练，可以大大缩短训练时间。这是因为在普通的训练中，会使用随机数来初始化神经网络，因此学习起来很慢，而在迁移学习中，使用一个已经在大规模数据集上训练好的模型，再进行微调，就可以大大缩短训练时间，并提高效果。

CreateML使用的基础模型叫VisionFeaturePrint_Screen，这是使用ImageNet训练的数据集，因此在图像分类方面效果很好。这个模型实际是在提取特征，输出是一个2048维的向量，然后CreateML使用逻辑回归，对提取出的特征进行分类。

在训练过程中会发现过拟合的现象，可以通过增加图片来改善。CreateML提供了一些参数可以选择，通过对原图片进行镜像、翻转、旋转等操作，构建出更多的训练数据。
![](img/Attachment.png
)

## 模型验证与导出
训练结束后，可以对模型进行命名，并导出为CoreML格式的模型，然后就可以像第二章那样在应用中使用。
![](img/Attachment1.png
)
## 总结
在这一章我们学习了如何使用CreateML训练自己的CoreML模型。CreateML非常容易使用，但是只允许我们在训练过程中调整很少的参数，而且在文本分类方面也有不足，接着我们会学习如何使用TuriCreate Python工具包训练更完备的模型。
TODO: 会尝试使用训练的模型开发一个实时监测食物类别的应用。

## 开发一个实时的食物分类应用
主要的难点在于视频的捕获，其他部分和第二章开发的食品是否健康分类类似

![](img/RPReplay_Final1590127420.mp4)
